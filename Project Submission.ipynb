{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling in Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Stock Symbols that make up SOXL and  getting historical financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stock symbols\n",
    "stock_symbols = ['NVDA', 'AVGO', 'AMD', 'QCOM', 'MU']\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2024-10-01'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the Data itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for NVDA:\n",
      "                               Open      High       Low     Close     Volume  \\\n",
      "Date                                                                           \n",
      "2019-01-02 00:00:00-05:00  3.239936  3.434371  3.225303  3.378322  508752000   \n",
      "2019-01-03 00:00:00-05:00  3.318057  3.352034  3.166775  3.174215  705552000   \n",
      "2019-01-04 00:00:00-05:00  3.247376  3.415771  3.216623  3.377578  585620000   \n",
      "2019-01-07 00:00:00-05:00  3.434868  3.593343  3.383531  3.556390  709160000   \n",
      "2019-01-08 00:00:00-05:00  3.637984  3.640216  3.395187  3.467853  786016000   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "2019-01-02 00:00:00-05:00        0.0           0.0  \n",
      "2019-01-03 00:00:00-05:00        0.0           0.0  \n",
      "2019-01-04 00:00:00-05:00        0.0           0.0  \n",
      "2019-01-07 00:00:00-05:00        0.0           0.0  \n",
      "2019-01-08 00:00:00-05:00        0.0           0.0  \n",
      "\n",
      "Data for AVGO:\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2019-01-02 00:00:00-05:00  20.859342  21.349705  20.661519  21.249956   \n",
      "2019-01-03 00:00:00-05:00  20.499742  20.665711  19.306943  19.359751   \n",
      "2019-01-04 00:00:00-05:00  19.638883  19.819940  19.419266  19.550030   \n",
      "2019-01-07 00:00:00-05:00  19.585235  20.137629  19.342987  19.948189   \n",
      "2019-01-08 00:00:00-05:00  20.126730  20.276774  19.561764  19.788086   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2019-01-02 00:00:00-05:00  30346000        0.0           0.0  \n",
      "2019-01-03 00:00:00-05:00  68580000        0.0           0.0  \n",
      "2019-01-04 00:00:00-05:00  54248000        0.0           0.0  \n",
      "2019-01-07 00:00:00-05:00  53433000        0.0           0.0  \n",
      "2019-01-08 00:00:00-05:00  36795000        0.0           0.0  \n",
      "\n",
      "Data for AMD:\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2019-01-02 00:00:00-05:00  18.010000  19.000000  17.980000  18.830000   \n",
      "2019-01-03 00:00:00-05:00  18.420000  18.680000  16.940001  17.049999   \n",
      "2019-01-04 00:00:00-05:00  17.549999  19.070000  17.430000  19.000000   \n",
      "2019-01-07 00:00:00-05:00  19.440001  20.680000  19.000000  20.570000   \n",
      "2019-01-08 00:00:00-05:00  21.190001  21.200001  19.680000  20.750000   \n",
      "\n",
      "                              Volume  Dividends  Stock Splits  \n",
      "Date                                                           \n",
      "2019-01-02 00:00:00-05:00   87148700        0.0           0.0  \n",
      "2019-01-03 00:00:00-05:00  117277600        0.0           0.0  \n",
      "2019-01-04 00:00:00-05:00  111878600        0.0           0.0  \n",
      "2019-01-07 00:00:00-05:00  107157000        0.0           0.0  \n",
      "2019-01-08 00:00:00-05:00  121271000        0.0           0.0  \n",
      "\n",
      "Data for QCOM:\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2019-01-02 00:00:00-05:00  48.764273  50.326118  48.521317  49.805504   \n",
      "2019-01-03 00:00:00-05:00  48.547348  49.319593  48.174241  48.330425   \n",
      "2019-01-04 00:00:00-05:00  49.024583  49.310923  47.905260  49.111351   \n",
      "2019-01-07 00:00:00-05:00  48.929135  49.597258  48.547352  48.972519   \n",
      "2019-01-08 00:00:00-05:00  49.206792  49.354302  48.252333  48.547348   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2019-01-02 00:00:00-05:00   9896600        0.0           0.0  \n",
      "2019-01-03 00:00:00-05:00  14422200        0.0           0.0  \n",
      "2019-01-04 00:00:00-05:00  14177300        0.0           0.0  \n",
      "2019-01-07 00:00:00-05:00  12352000        0.0           0.0  \n",
      "2019-01-08 00:00:00-05:00  12110000        0.0           0.0  \n",
      "\n",
      "Data for MU:\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2019-01-02 00:00:00-05:00  30.419370  32.460414  30.174053  32.136593   \n",
      "2019-01-03 00:00:00-05:00  31.224008  31.547829  30.281990  30.419367   \n",
      "2019-01-04 00:00:00-05:00  31.067007  32.421160  30.959066  32.087528   \n",
      "2019-01-07 00:00:00-05:00  33.068798  33.804750  32.686103  33.363178   \n",
      "2019-01-08 00:00:00-05:00  33.902878  33.942129  32.195470  33.108051   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2019-01-02 00:00:00-05:00  26004300        0.0           0.0  \n",
      "2019-01-03 00:00:00-05:00  29145500        0.0           0.0  \n",
      "2019-01-04 00:00:00-05:00  28557300        0.0           0.0  \n",
      "2019-01-07 00:00:00-05:00  44841500        0.0           0.0  \n",
      "2019-01-08 00:00:00-05:00  33434100        0.0           0.0  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = {} # create an empty dictionary for storage of data\n",
    "\n",
    "#Looping through the dictionary\n",
    "for symbol in stock_symbols:\n",
    "    #Getting the data from the API\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    data[symbol] = ticker.history(start = start_date, end = end_date)\n",
    "\n",
    "#printing the data\n",
    "\n",
    "for symbol, df in data.items():\n",
    "    print(f'Data for {symbol}:')\n",
    "    print(df.head()) # printing the first 5 rows of the data for a small glance\n",
    "    print()\n",
    "\n",
    "stock_data = pd.concat(data, keys = data.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.to_csv('stock_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape News articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\rayli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rayli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rayli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rayli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rayli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "# from dotenv import load_dotenv\n",
    "import os\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# load environment variables from .env file\n",
    "os.environ['TAVILY_API_KEY'] = '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'\n",
    "\n",
    "# connect\n",
    "client = TavilyClient(api_key=os.environ.get(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nvida news articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully!\n"
     ]
    }
   ],
   "source": [
    "result = client.search(\"NVIDIA news articles with summary\", \n",
    "                       include_answer=True, \n",
    "                       parameters={\"answer_type\": \"news\", \"summary\": True})\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "df = pd.DataFrame([{\"title\": result[\"title\"], \"summary\": result[\"summary\"]}])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('nvidia_news_articles_with_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'NVIDIA news articles with summary', 'follow_up_questions': None, 'answer': \"NVIDIA recently announced collaborations with Google Quantum AI for quantum computing device design, the adoption of NVIDIA BioNeMo Framework in drug discovery, and working with the cloud-native community to advance AI and ML. Jensen Huang, NVIDIA's CEO, unveiled new cloud services supporting AI workflows and the launch of next-gen RTX GPUs during the recent GTC keynote. The company is also partnering with Deloitte to bring AI and Omniverse services to enterprises. NVIDIA's Omniverse is gaining wide adoption, with new products like the Jetson Orin Nano for Robotics being introduced.\", 'images': [], 'results': [{'title': 'News Archive | NVIDIA Newsroom', 'url': 'https://nvidianews.nvidia.com/news', 'content': 'News Archive | NVIDIA Newsroom About NVIDIA NVIDIA Blog NVIDIA Blog NVIDIA Blog SC24 -- NVIDIA today announced an NVIDIA Omniverse™ Blueprint that enables industry software developers to help their computer-aided engineering (CAE) customers in aerospace, automotive, manufacturing, energy and other industries create digital ... NVIDIA today announced it is working with Google Quantum AI to accelerate the design of its next-generation quantum computing devices using simulations powered by the NVIDIA CUDA-Q™ platform. NVIDIA today announced that global pharmaceutical and techbio industry leaders, academic pioneers and AI researchers are adopting the open-source NVIDIA® BioNeMo™ Framework to advance drug discovery and accelerate molecule design. Open for Development: NVIDIA Works With Cloud-Native Community to Advance AI and ML About NVIDIA NVIDIA Blog', 'score': 0.97796774, 'raw_content': None}, {'title': 'Keynote Wrap-Up: NVIDIA CEO Unveils Next-Gen RTX GPUs, AI Workflows in ...', 'url': 'https://blogs.nvidia.com/blog/keynote-gtc-nvidia-ceo/', 'content': 'All NVIDIA News\\nInstant Latte: NVIDIA Gen AI Research Brews 3D Shapes in Under a Second\\n‘You Transformed the World,’ NVIDIA CEO Tells Researchers Behind Landmark AI Paper\\nAI Decoded From GTC: The Latest Developer Tools and Apps Accelerating AI on PC and Workstation\\nSecure by Design: NVIDIA AIOps Partner Ecosystem Blends AI for Businesses\\nClimate Pioneers: 3 Startups Harnessing NVIDIA’s AI and Earth-2 Platforms\\nPost navigation\\nCorporate Information\\nGet Involved\\nNews & Events\\nNVIDIA websites use cookies to deliver and improve the website experience. Thor will be the processor for robotics, medical instruments, industrial automation and edge AI systems, Huang said.\\n3.5 Million Developers, 3,000 Accelerated Applications\\nBringing NVIDIA’s systems and silicon, and the benefits of accelerated computing, to industries around the world, is a software ecosystem with more than 3.5 million developers creating some 3,000 accelerated apps using NVIDIA’s 550 software development kits, or SDKs, and AI models, Huang announced.\\n Deloitte to Bring AI, Omniverse Services to Enterprises\\nAnd to speed the adoption of all these technologies to the world’s enterprises, Deloitte, the world’s largest professional services firm, is bringing new services built on NVIDIA AI and NVIDIA Omniverse to the world’s enterprises, Huang announced.\\n Keynote Wrap-Up: NVIDIA CEO Unveils Next-Gen RTX GPUs, AI Workflows in the Cloud\\nNew cloud services to support AI workflows and the launch of a new generation of GeForce RTX GPUs featured today in NVIDIA CEO Jensen Huang’s GTC keynote, which was packed with new systems, silicon, and software.\\n Omniverse is seeing wide adoption, and Huang shared several customer stories and demos:\\nNew Jetson Orin Nano for Robotics\\nShifting from virtual worlds to machines that will move through their world, robotic computers “are the newest types of computers,” Huang said, describing NVIDIA’s second-generation processor for robotics, Orin, as a homerun.\\n', 'score': 0.97324073, 'raw_content': None}, {'title': 'Nvidia, Powered by A.I. Boom, Reports Soaring Revenue and Profits', 'url': 'https://www.nytimes.com/2024/05/22/technology/nvidia-quarterly-earnings-results.html', 'content': 'The company reported revenue of $26 billion in its latest quarter, tripling its sales from a year earlier. Jim Wilson/The New York Times. Nvidia, which makes microchips that power most artificial', 'score': 0.86703575, 'raw_content': None}, {'title': \"Nvidia's Q3 profit and revenue surge on AI chip demand | AP News\", 'url': 'https://apnews.com/article/nvidia-ai-earnings-report-adc942aa0e0c5d1a550b7bad486b942a', 'content': \"Nvidia's Q3 profit and revenue surge on AI chip demand | AP News AP Top 25 AP Top 25 AP Top 25 NFL NBA NHL Men’s College Basketball Women’s College Basketball MLB Auto Racing Movie Reviews What to Stream Television Book Reviews Music Celebrity Interviews Back to school Food & Recipes Gardening Homes Travel Fashion Pets LOS ANGELES (AP) — Nvidia on Wednesday reported a surge in third-quarter profit and sales as demand for its specialized computer chips that power artificial intelligence systems remains robust. Nvidia has led the artificial intelligence sector to become one of the stock market’s biggest companies, as tech giants spend heavily on the company’s chips and data centers needed to train and operate their AI systems.\", 'score': 0.84117436, 'raw_content': None}, {'title': 'Latest News - NVIDIA Newsroom', 'url': 'https://nvidianews.nvidia.com/news/latest', 'content': 'What Is a SuperNIC?\\nNVIDIA’s New Ethernet Networking Platform for AI Available Soon From Dell Technologies, Hewlett Packard Enterprise, Lenovo\\nFrom Guangzhou to Los Angeles, Automakers Dazzle With AI-Powered Vehicles\\nAI to See “Major Second Wave,” NVIDIA CEO Says in Fireside Chat With iliad Group Exec\\nDropbox and NVIDIA Team to Bring Personalized Generative AI to Millions of Customers\\nNVIDIA and Scaleway Speed Development for European Startups and Enterprises\\nAI Training AI: GatorTronGPT at the Forefront of University of Florida’s Medical AI Innovations\\nThree Ways Generative AI Can Bolster Cybersecurity\\nInto the Omniverse: OpenUSD Enhancements for Autodesk Maya Make 3D Workflows a Ferret-Tale\\nMore Games, More Wins: PC Game Pass Included With Six-Month GeForce NOW Memberships\\nRinging in the Future: Aspiring Computer Science Major Experiences NVIDIA Life With Make-A-Wish Visit\\nAI-Powered Tech Company Helps Grocers Start Afresh in Supply Chain Management\\nNVIDIA Announces Financial Results for Third Quarter Fiscal 2024\\nNVIDIA Collaborates With Genentech to Accelerate Drug Discovery Using Generative AI\\n3D Artist Cooks Up Stunningly Photorealistic Food Renders This Week ‘In the NVIDIA Studio’\\n NVIDIA and Amdocs Bring Custom Generative AI to Global Telco Industry\\nIn the Fast Lane: NVIDIA Announces Omniverse Cloud Services on Microsoft Azure to Accelerate Automotive Digitalization\\nNew NVIDIA H100, H200 Tensor Core GPU Instances Coming to Microsoft Azure to Accelerate AI What Is Retrieval-Augmented Generation?\\nIgniting the Future: TensorRT-LLM Release Accelerates AI Inference Performance, Adds Support for New Models Running on RTX-Powered Windows 11 PCs\\nNVIDIA Introduces Generative AI Foundry Service on Microsoft Azure for Enterprises and Startups Worldwide\\nChallenge Accepted: Animator Wade Neistadt Leads Robotic Revolution in Record Time Latest News\\nHungry for Gaming: 18 New Games to Join GeForce NOW\\nNVIDIA Announces Upcoming Events for Financial Community\\nTeenage Dream:', 'score': 0.81669897, 'raw_content': None}], 'response_time': 4.1}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping and Analyzing news articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMD news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMD news articles saved successfully!\n"
     ]
    }
   ],
   "source": [
    "result = client.search(\"Advanced Micro Devices news articles with summary\", \n",
    "                       include_answer=True, \n",
    "                       parameters={\"answer_type\": \"news\", \"summary\": True})\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Extract articles\n",
    "data = []\n",
    "for article in result.get(\"results\", []):  # Iterate through the results list\n",
    "    data.append({\n",
    "        \"title\": article.get(\"title\", \"No Title\"),   # Default if 'title' is missing\n",
    "        \"summary\": article.get(\"content\", \"No Summary\")  # Use 'content' for summaries\n",
    "    })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('AMD_news_articles_with_summary.csv', index=False)\n",
    "\n",
    "print(\"AMD news articles saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualcomm Incorporated news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualcomm news articles saved successfully!\n"
     ]
    }
   ],
   "source": [
    "result = client.search(\"Qualcomm Incorporated news articles with summary\", \n",
    "                       include_answer=True, \n",
    "                       parameters={\"answer_type\": \"news\", \"summary\": True})\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Extract articles\n",
    "data = []\n",
    "for article in result.get(\"results\", []):  # Iterate through the results list\n",
    "    data.append({\n",
    "        \"title\": article.get(\"title\", \"No Title\"),   # Default if 'title' is missing\n",
    "        \"summary\": article.get(\"content\", \"No Summary\")  # Use 'content' for summaries\n",
    "    })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('Qualcomm_Inc_news_articles_with_summary.csv', index=False)\n",
    "\n",
    "print(\"Qualcomm news articles saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcom news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcom news articles saved successfully!\n"
     ]
    }
   ],
   "source": [
    "result = client.search(\"Broadcom news articles with summary\", \n",
    "                       include_answer=True, \n",
    "                       parameters={\"answer_type\": \"news\", \"summary\": True})\n",
    "\n",
    "\n",
    "# Extract articles\n",
    "data = []\n",
    "for article in result.get(\"results\", []):  # Iterate through the results list\n",
    "    data.append({\n",
    "        \"title\": article.get(\"title\", \"No Title\"),   # Default to \"No Title\" if missing\n",
    "        \"summary\": article.get(\"content\", \"No Summary\")  # Use 'content' for summaries\n",
    "    })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('Broadcom_news_articles_with_summary.csv', index=False)\n",
    "\n",
    "print(\"Broadcom news articles saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micron News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micron news articles saved successfully!\n"
     ]
    }
   ],
   "source": [
    "result = client.search(\"Micron Technology news articles with summary\", \n",
    "                       include_answer=True, \n",
    "                       parameters={\"answer_type\": \"news\", \"summary\": True})\n",
    "\n",
    "\n",
    "# Extract articles\n",
    "data = []\n",
    "for article in result.get(\"results\", []):  # Iterate through the results list\n",
    "    data.append({\n",
    "        \"title\": article.get(\"title\", \"No Title\"),   # Default to \"No Title\" if missing\n",
    "        \"summary\": article.get(\"content\", \"No Summary\")  # Use 'content' for summaries\n",
    "    })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('Micron_Tech_news_articles_with_summary.csv', index=False)\n",
    "\n",
    "print(\"Micron news articles saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
